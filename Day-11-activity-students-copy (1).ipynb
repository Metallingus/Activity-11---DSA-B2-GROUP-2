{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDe0EDhPlWOT"
   },
   "source": [
    "\n",
    "### Supervised Learning\n",
    "### Activity: Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SptfnHBzlWOX"
   },
   "source": [
    "### Question 1 - Classification vs. Regression\n",
    "*Your goal for this project is to identify students who might need early intervention before they fail or pass. Which type of supervised learning problem is this, classification or regression? Why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8IVblKIlWOY"
   },
   "source": [
    "**Answer: ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6O1lcXl4kYB"
   },
   "source": [
    "Given how the output of the model should be binary (Either a yes or a no), Classification models should be preferably used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEFSPhwFlWOY"
   },
   "source": [
    "### Question-2\n",
    "load necessary Python libraries and load the student data. Note that the last column from this dataset, `'passed'`, will be our target label (whether the student graduated or didn't graduate). All other columns are features about each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F3dptovEPJho"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lbtZHw88lWOY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  internet romantic  famrel  freetime  goout Dalc Walc health absences passed  \n",
       "0       no       no       4         3      4    1    1      3        6     no  \n",
       "1      yes       no       5         3      3    1    1      3        4     no  \n",
       "2      yes       no       4         3      2    2    3      3       10    yes  \n",
       "3      yes      yes       3         2      2    1    1      5        2    yes  \n",
       "4       no       no       4         3      2    1    2      5        4    yes  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3AephYplWOZ"
   },
   "source": [
    "### Question-3\n",
    "Let's begin by investigating the dataset to determine how many students we have information on, and learn about the graduation rate among these students. In the code cell below, you will need to compute the following:\n",
    "- The total number of students, `n_students`.\n",
    "- The total number of features for each student, `n_features`.\n",
    "- The number of those students who passed, `n_passed`.\n",
    "- The number of those students who failed, `n_failed`.\n",
    "- The graduation rate of the class, `grad_rate`, in percent (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1hRa3td44kYN"
   },
   "outputs": [],
   "source": [
    "# Calculate number of students\n",
    "n_students = len(student_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eqU6jPVK4kYP"
   },
   "outputs": [],
   "source": [
    "# Calculate number of features\n",
    "n_features = len(student_data.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PvU0qTM04kYR"
   },
   "outputs": [],
   "source": [
    "# Calculate passing students\n",
    "n_passed = len(student_data[(student_data.passed == 'yes')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2uCtyJzL4kYS"
   },
   "outputs": [],
   "source": [
    "# Calculate failing students\n",
    "n_failed = len(student_data[(student_data.passed == 'no')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "doBB3xvr4kYT"
   },
   "outputs": [],
   "source": [
    "# Calculate graduation rate\n",
    "grad_rate = float(n_passed)/float(n_students)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "URNDX0oVlWOa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of features: 30\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print (\"Total number of students: {}\".format(n_students))\n",
    "print (\"Number of features: {}\".format(n_features))\n",
    "print (\"Number of students who passed: {}\".format(n_passed))\n",
    "print (\"Number of students who failed: {}\".format(n_failed))\n",
    "print (\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmMGgYZBlWOb"
   },
   "source": [
    "## Preparing the Data\n",
    "you will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Question-4 Identify feature and target columns\n",
    "\n",
    "\n",
    "separate the student data into feature and target columns to see if any features are non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GgiZoA254kYV"
   },
   "outputs": [],
   "source": [
    "# Extract feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IjAE3b3k4kYV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature values:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = list(student_data.columns[:-1])\n",
    "print (\"Feature values:\\n{}\".format(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DhFVfFV_4kYV"
   },
   "outputs": [],
   "source": [
    "# Extract target column 'passed'\n",
    "target_col = student_data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "50-dIZYb4kYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target column: passed\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nTarget column: {}\".format(target_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V1K7Mwny4kYW"
   },
   "outputs": [],
   "source": [
    "# Separate the data into feature data and target data (X and y, respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZtO7akyFlWOb"
   },
   "outputs": [],
   "source": [
    "X = student_data[feature_cols]\n",
    "y = student_data[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI7sSCC4lWOc"
   },
   "source": [
    "### Question-5 Preprocess Feature Columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation. Run the code cell below to perform the preprocessing routine discussed in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YeSgrfbp4kYZ"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        if col_data.dtype == object:\n",
    "\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Kji5t1434kYa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "X = preprocess_features(X)\n",
    "print (\"Processed feature columns ({} total features):\\n{}\".format(len(X.columns), list(X.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J86VuLh_lWOd"
   },
   "source": [
    "### Question - 6 Implementation: Training and Testing Data Split\n",
    "So far, we have converted all _categorical_ features into numeric values. For the next step, we split the data (both features and corresponding labels) into training and test sets. you will need to implement the following:\n",
    "- Randomly shuffle and split the data (`X`, `y`) into training and testing subsets.\n",
    "  - Use 300 training points (approximately 75%) and 95 testing points (approximately 25%).\n",
    "  - Set a `random_state` for the function(s) you use, if provided.\n",
    "  - Store the results in `X_train`, `X_test`, `y_train`, and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Mqp127V34kYb"
   },
   "outputs": [],
   "source": [
    "# splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "num_train = 300\n",
    "num_test = X.shape[0] - num_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=num_test, train_size=num_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "J6JCo-XGlWOd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 300 samples.\n",
      "Testing set has 95 samples.\n"
     ]
    }
   ],
   "source": [
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTRH20jwlWOe"
   },
   "source": [
    "### Question - 7  Training and Evaluating Models\n",
    "In this section, you will choose 3 supervised learning models that are appropriate for this problem and available in `scikit-learn`. You will first discuss the reasoning behind choosing these three models by considering what you know about the data and each model's strengths and weaknesses. You will then fit the model to varying sizes of training data and measure the accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37OQDnbY4kYd"
   },
   "source": [
    "The three model from scikit-learn that seems to fit appropriately for this model are Decision Trees Classifier, Random Forest algorithm and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xRj142alWOe"
   },
   "source": [
    "###  Model Application\n",
    "*List three supervised learning models that are appropriate for this problem. What are the general applications of each model? What are their strengths and weaknesses? Given what you know about the data, why did you choose these models to be applied?*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ccZlSV6R4kYe"
   },
   "source": [
    "#explaination\n",
    "Decision Trees Classifier:\n",
    "\n",
    "Decision tree classifiers are appealing models if we are willing to commentate. As the name decision \n",
    "tree offers, we can think of this model as splitting our data by making decisions based on asking a \n",
    "bunch of questions. \n",
    "\n",
    "Using the decision tree algorithm, we start at the tree root and seperate the data on the feature that\n",
    "results in the largest information gain (IG). In an iterative process, we can then repeat this \n",
    "seperation process at each child node until the leaves are branchless. That is the samples at each \n",
    "node all belong to the same class. In practice, this can result in a very deep tree with many nodes,\n",
    "which can easily lead to overfitting. Thus, we typically want to prune the tree by setting a limit for \n",
    "the maximal depth of the tree.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Easy to understand.\n",
    "Able to handle descrete inputs.\n",
    "Able to handle continuous inputs using decision boundaries.\n",
    "Using Information Gain, decides how to split the decision boundaries for the dataset.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Exponentially growing nodes.\n",
    "When maximum depth is too high, the model is prone to overfit. \n",
    "Bad performance when ID3 (Iterative Dichotomiser 3) algorithm could not split the data near by the top.\n",
    "\n",
    "#Support Vector Machine Classifier:\n",
    "\n",
    "Support vector machine (SVM), which can be esteemed as a generaliation of the perceptron. Using the perceptron\n",
    "algorithm, we minimized misclassification errors. However, in SVMs, our optimization target is to maximize \n",
    "the margin. The margin is defined as the distance between the separating hyperplane (decision boundary) \n",
    "and the training samples that are closest to this hyperplane, which are the so-called support\n",
    "vectors.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "They are powerful kernels. \n",
    "SVMs avoid overfitting by choosing a specific hyperplane among the many that can separate the data in\n",
    "the feature space. \n",
    "SVMs find the maximum margin hyperplane, the hyperplane that maximixes the minimum distance from the \n",
    "hyperplane to the closest training point.\n",
    "\n",
    "Disadvantage:\n",
    "\n",
    "Overfitting is a problem when we have too many features. \n",
    "The biggest limitation of the support vector approach lies in choice of the kernel.\n",
    "\n",
    "#Random Forest Classifier (as an Ensemble Method):\n",
    "    \n",
    "The random forest algorithm can be summarized in four simple steps:\n",
    "1. Draw a random bootstrap sample of size n (randomly choose n samples from the training set with replacement).\n",
    "2. Grow a decision tree from the bootstrap sample. At each node:\n",
    "   a) Randomly select d features without replacement.\n",
    "   b) Split the node using the feature that provides the best split according to the objective function,\n",
    "    for instance, by maximizing the information gain.\n",
    "3. Repeat the steps 1 to 2 k times.\n",
    "4. Aggregate the prediction by each tree to assign the class label by majority vote.\n",
    "\n",
    "Although random forests don't offer the same level of interpretability as decision trees, a big advantage\n",
    "of random forests is that we don't have to worry so much about choosing good hyperparameter values. We\n",
    "typically don't need to prune the random forest since the ensemble model is quite robust to noise from \n",
    "the individual decision trees.\n",
    "\n",
    "Application:\n",
    "    \n",
    "Internet traffic interception\n",
    "Video/image/voice classification\n",
    "\n",
    "\n",
    "Advantages:\n",
    "    \n",
    "It scales quickly. \n",
    "They have ability to deal with unbalanced and missing data.\n",
    "\n",
    "Disadvantages:\n",
    "    \n",
    "Overfits if there is noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qZBC-_zXLMNA"
   },
   "outputs": [],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yHqh3ZGJ4kYe"
   },
   "outputs": [],
   "source": [
    "# fit model-1  on traning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EqkgnUdDLN2X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model=DecisionTreeClassifier()\n",
    "dt_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AC7EhVEY4kYf"
   },
   "outputs": [],
   "source": [
    "# predict on the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "eBlGN2APLdFV"
   },
   "outputs": [],
   "source": [
    "y_pred=dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HxZy4JB74kYg"
   },
   "outputs": [],
   "source": [
    "# calculate the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HiOuH5RKLqh2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:\n",
      " 0.6526315789473685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy_score:\\n',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Yv1bGADM4kYg"
   },
   "outputs": [],
   "source": [
    "# fit the model-2 on traning data and predict on the test data and measure the accuracy\n",
    "from sklearn.svm import SVC\n",
    "svm_linear=SVC(kernel='rbf')\n",
    "svm_linear.fit(X_train,y_train)\n",
    "y_pred=svm_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MWU62VfAMxah"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:\n",
      " 0.6210526315789474\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:\\n',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Ne4vREKf4kYh"
   },
   "outputs": [],
   "source": [
    "# fit the model-3 on traning data and predict on the test data and measure the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "IZOpKl0_NOdi"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "AgzEd_eT4kYi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:\n",
      " 0.6631578947368421\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:\\n',accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day-11-activity-students-copy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
